{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Movie Reviews: Sentiment analysis </h1>\n",
    "<h2> Author: Rashmith Reddy Boppidi </h2>\n",
    "    <p1>\n",
    "    <ol> \n",
    "    <li> Importing the required packages </li>\n",
    "    <li> Reading the data </li> \n",
    "    <li> Text Preprocessing </li>\n",
    "    <li> Feature exctraction ( Preparing data to fit the model ) </li>\n",
    "    <li> Text Preprocessing </li>\n",
    "    <li> Training and model evaluation </li>\n",
    "    </ol>\n",
    "    </p1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Importing the required packages </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Reading the data <h2/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = pd.read_csv(\"train.csv\")\n",
    "c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Text Preprocessing <h2/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = []\n",
    "for i in c[\"text\"]:\n",
    "    x = word_tokenize(i) #we are tokenizing the text ( we can either tokenize as word or sentense )\n",
    "    x = [x.lower() for x in x if x.isalnum()]  #avoid punctuations \n",
    "    x = [lem.lemmatize(x) for x in x if x not in stop_words] #remove stop words and lematize it ( you can either your stemmer)\n",
    "    k.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[\"tokenized\"] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>[grew, b, 1965, watching, loving, thunderbird,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>[put, movie, dvd, player, sat, coke, chip, exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "      <td>[people, know, particular, time, past, like, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[even, though, great, interest, biblical, movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "      <td>[im, die, hard, dad, army, fan, nothing, ever,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>\"Western Union\" is something of a forgotten cl...</td>\n",
       "      <td>1</td>\n",
       "      <td>[western, union, something, forgotten, classic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>This movie is an incredible piece of work. It ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[movie, incredible, piece, work, explores, eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>My wife and I watched this movie because we pl...</td>\n",
       "      <td>0</td>\n",
       "      <td>[wife, watched, movie, plan, visit, sicily, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>When I first watched Flatliners, I was amazed....</td>\n",
       "      <td>1</td>\n",
       "      <td>[first, watched, flatliners, amazed, necessary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>Why would this film be so good, but only gross...</td>\n",
       "      <td>1</td>\n",
       "      <td>[would, film, good, gross, estimated, award, n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "0      I grew up (b. 1965) watching and loving the Th...      0   \n",
       "1      When I put this movie in my DVD player, and sa...      0   \n",
       "2      Why do people who do not know what a particula...      0   \n",
       "3      Even though I have great interest in Biblical ...      0   \n",
       "4      Im a die hard Dads Army fan and nothing will e...      1   \n",
       "...                                                  ...    ...   \n",
       "39995  \"Western Union\" is something of a forgotten cl...      1   \n",
       "39996  This movie is an incredible piece of work. It ...      1   \n",
       "39997  My wife and I watched this movie because we pl...      0   \n",
       "39998  When I first watched Flatliners, I was amazed....      1   \n",
       "39999  Why would this film be so good, but only gross...      1   \n",
       "\n",
       "                                               tokenized  \n",
       "0      [grew, b, 1965, watching, loving, thunderbird,...  \n",
       "1      [put, movie, dvd, player, sat, coke, chip, exp...  \n",
       "2      [people, know, particular, time, past, like, f...  \n",
       "3      [even, though, great, interest, biblical, movi...  \n",
       "4      [im, die, hard, dad, army, fan, nothing, ever,...  \n",
       "...                                                  ...  \n",
       "39995  [western, union, something, forgotten, classic...  \n",
       "39996  [movie, incredible, piece, work, explores, eve...  \n",
       "39997  [wife, watched, movie, plan, visit, sicily, st...  \n",
       "39998  [first, watched, flatliners, amazed, necessary...  \n",
       "39999  [would, film, good, gross, estimated, award, n...  \n",
       "\n",
       "[40000 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in c[\"tokenized\"]:\n",
    "    x = ' '.join(i) #join the preprocessed text\n",
    "    l.append(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "c[\"joined_tokens\"] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>joined_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>[grew, b, 1965, watching, loving, thunderbird,...</td>\n",
       "      <td>grew b 1965 watching loving thunderbird mate s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>[put, movie, dvd, player, sat, coke, chip, exp...</td>\n",
       "      <td>put movie dvd player sat coke chip expectation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "      <td>[people, know, particular, time, past, like, f...</td>\n",
       "      <td>people know particular time past like feel nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[even, though, great, interest, biblical, movi...</td>\n",
       "      <td>even though great interest biblical movie bore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "      <td>[im, die, hard, dad, army, fan, nothing, ever,...</td>\n",
       "      <td>im die hard dad army fan nothing ever change g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>\"Western Union\" is something of a forgotten cl...</td>\n",
       "      <td>1</td>\n",
       "      <td>[western, union, something, forgotten, classic...</td>\n",
       "      <td>western union something forgotten classic west...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>This movie is an incredible piece of work. It ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[movie, incredible, piece, work, explores, eve...</td>\n",
       "      <td>movie incredible piece work explores every noo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>My wife and I watched this movie because we pl...</td>\n",
       "      <td>0</td>\n",
       "      <td>[wife, watched, movie, plan, visit, sicily, st...</td>\n",
       "      <td>wife watched movie plan visit sicily stromboli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>When I first watched Flatliners, I was amazed....</td>\n",
       "      <td>1</td>\n",
       "      <td>[first, watched, flatliners, amazed, necessary...</td>\n",
       "      <td>first watched flatliners amazed necessary feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>Why would this film be so good, but only gross...</td>\n",
       "      <td>1</td>\n",
       "      <td>[would, film, good, gross, estimated, award, n...</td>\n",
       "      <td>would film good gross estimated award nominati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "0      I grew up (b. 1965) watching and loving the Th...      0   \n",
       "1      When I put this movie in my DVD player, and sa...      0   \n",
       "2      Why do people who do not know what a particula...      0   \n",
       "3      Even though I have great interest in Biblical ...      0   \n",
       "4      Im a die hard Dads Army fan and nothing will e...      1   \n",
       "...                                                  ...    ...   \n",
       "39995  \"Western Union\" is something of a forgotten cl...      1   \n",
       "39996  This movie is an incredible piece of work. It ...      1   \n",
       "39997  My wife and I watched this movie because we pl...      0   \n",
       "39998  When I first watched Flatliners, I was amazed....      1   \n",
       "39999  Why would this film be so good, but only gross...      1   \n",
       "\n",
       "                                               tokenized  \\\n",
       "0      [grew, b, 1965, watching, loving, thunderbird,...   \n",
       "1      [put, movie, dvd, player, sat, coke, chip, exp...   \n",
       "2      [people, know, particular, time, past, like, f...   \n",
       "3      [even, though, great, interest, biblical, movi...   \n",
       "4      [im, die, hard, dad, army, fan, nothing, ever,...   \n",
       "...                                                  ...   \n",
       "39995  [western, union, something, forgotten, classic...   \n",
       "39996  [movie, incredible, piece, work, explores, eve...   \n",
       "39997  [wife, watched, movie, plan, visit, sicily, st...   \n",
       "39998  [first, watched, flatliners, amazed, necessary...   \n",
       "39999  [would, film, good, gross, estimated, award, n...   \n",
       "\n",
       "                                           joined_tokens  \n",
       "0      grew b 1965 watching loving thunderbird mate s...  \n",
       "1      put movie dvd player sat coke chip expectation...  \n",
       "2      people know particular time past like feel nee...  \n",
       "3      even though great interest biblical movie bore...  \n",
       "4      im die hard dad army fan nothing ever change g...  \n",
       "...                                                  ...  \n",
       "39995  western union something forgotten classic west...  \n",
       "39996  movie incredible piece work explores every noo...  \n",
       "39997  wife watched movie plan visit sicily stromboli...  \n",
       "39998  first watched flatliners amazed necessary feat...  \n",
       "39999  would film good gross estimated award nominati...  \n",
       "\n",
       "[40000 rows x 4 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Feature exctraction ( Preparing data to fit the model ) <h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p1> <b> They are two types of feature extractions mainly used : </b> </p1>\n",
    "\n",
    "<ol> \n",
    "    <li>BOW (Bag of words) </li>\n",
    "    <li>Tf-Idf (Term Frequency - Inverse Document Frequency) </li> </ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = TfidfVectorizer() #Here we are going to use Tf-Idf\n",
    "v = vec.fit_transform(c[\"joined_tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 38446)\t0.11641037786475152\n",
      "  (0, 24074)\t0.10317877692768666\n",
      "  (0, 34445)\t0.07288366225616721\n",
      "  (0, 69273)\t0.18356739945732245\n",
      "  (0, 62339)\t0.3249527150840115\n",
      "  (0, 33904)\t0.14566550509892945\n",
      "  (0, 44528)\t0.15647151354363142\n",
      "  (0, 59643)\t0.12871532258751248\n",
      "  (0, 1466)\t0.1059525335073119\n",
      "  (0, 45092)\t0.054704088106177814\n",
      "  (0, 59371)\t0.08421591990542834\n",
      "  (0, 12417)\t0.09395122352541688\n",
      "  (0, 61467)\t0.0953639336457156\n",
      "  (0, 76354)\t0.09540864979551203\n",
      "  (0, 26379)\t0.02611168399253787\n",
      "  (0, 78154)\t0.06657840292187796\n",
      "  (0, 34056)\t0.11265361771757607\n",
      "  (0, 14910)\t0.06262886638787547\n",
      "  (0, 76981)\t0.06464939551094384\n",
      "  (0, 12468)\t0.10248299111237723\n",
      "  (0, 20041)\t0.0495768759434987\n",
      "  (0, 31959)\t0.06476505501607285\n",
      "  (0, 27692)\t0.15647151354363142\n",
      "  (0, 38271)\t0.18356739945732245\n",
      "  (0, 16610)\t0.08297320213605737\n",
      "  :\t:\n",
      "  (39999, 40633)\t0.1107129267486208\n",
      "  (39999, 46285)\t0.10726340555162918\n",
      "  (39999, 4628)\t0.07824141815606554\n",
      "  (39999, 74137)\t0.0860005590829593\n",
      "  (39999, 7657)\t0.06622141267296272\n",
      "  (39999, 11184)\t0.09503518484653621\n",
      "  (39999, 38211)\t0.09464381028566339\n",
      "  (39999, 62632)\t0.06496946206333763\n",
      "  (39999, 71961)\t0.0620414491526374\n",
      "  (39999, 5628)\t0.12380424073292397\n",
      "  (39999, 34132)\t0.10432402924713027\n",
      "  (39999, 18080)\t0.09380975502516865\n",
      "  (39999, 30724)\t0.11912238759025424\n",
      "  (39999, 24434)\t0.052206041100651676\n",
      "  (39999, 78264)\t0.05974946986637667\n",
      "  (39999, 42365)\t0.06649075598459075\n",
      "  (39999, 43898)\t0.052327352613981575\n",
      "  (39999, 39929)\t0.12680228194283671\n",
      "  (39999, 62798)\t0.0586140759049011\n",
      "  (39999, 58381)\t0.09273624309018119\n",
      "  (39999, 67075)\t0.11261396429140778\n",
      "  (39999, 30222)\t0.049515528789426194\n",
      "  (39999, 24867)\t0.12688431220875607\n",
      "  (39999, 26379)\t0.03865638095173341\n",
      "  (39999, 79779)\t0.051682821468687475\n"
     ]
    }
   ],
   "source": [
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Training and model evaluation </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p1> We have used logistic regression - logistic function or sigmoid function which maintains output between 0 and 1 bets for the binary classification. </p1>\n",
    "<p2> For Model Evaluation we have used metrics: precision, recall, f1-score. We can simply use <b>accuracy score </b> too </p2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88      3941\n",
      "           1       0.88      0.90      0.89      4059\n",
      "\n",
      "    accuracy                           0.89      8000\n",
      "   macro avg       0.89      0.89      0.89      8000\n",
      "weighted avg       0.89      0.89      0.89      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(v, c['label'], test_size = 0.2,random_state = 0)\n",
    "\n",
    "lr_model = LogisticRegression(max_iter = 300)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "test_pred = lr_model.predict(X_test)\n",
    "print(classification_report(y_test,test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
